# 对生成对抗网络(GAN)的简单实现
该项目展示了如何使用PyTorch实现一个简单的生成对抗网络(GAN)来生成手写数字图像。我们使用MNIST数据集进行训练，并定义了生成器和判别器模型。

## 网络架构

### 生成器 (Generator)
生成器是一个全连接神经网络，将128维的随机噪声向量映射到28×28的图像空间：
- 输入层：128维随机噪声
- 隐藏层1：128 → 256，ReLU激活
- 隐藏层2：256 → 512，ReLU激活
- 隐藏层3：512 → 1024，ReLU激活
- 输出层：1024 → 784 (28×28)，Tanh激活

### 判别器 (Discriminator)
判别器是一个全连接神经网络，用于区分真实图像和生成的图像：
- 输入层：784 (28×28展平)
- 隐藏层1：784 → 1024，ReLU激活
- 隐藏层2：1024 → 512，ReLU激活
- 隐藏层3：512 → 256，ReLU激活
- 输出层：256 → 1，Sigmoid激活（输出0-1之间的概率）

## 算法描述

### GAN训练原理
GAN由两个网络组成，通过对抗训练的方式相互博弈：
1. **判别器(D)**：试图区分真实样本和生成样本
2. **生成器(G)**：试图生成足以欺骗判别器的假样本

### 训练流程
在每个训练迭代中：

1. **训练判别器**
   - 从真实数据集中采样真实图像，标签为1
   - 使用生成器生成假图像，标签为0
   - 计算判别器在真实和假样本上的损失
   - 反向传播更新判别器参数

2. **训练生成器**
   - 生成新的假图像
   - 将假图像送入判别器，但标签设为1（期望欺骗判别器）
   - 计算生成器损失
   - 反向传播更新生成器参数

### 损失函数
- 使用二元交叉熵损失 (Binary Cross Entropy, BCE)
- 判别器目标：最大化 $\log D(x) + \log(1 - D(G(z)))$
- 生成器目标：最大化 $\log D(G(z))$



## 使用方法

### 数据准备
项目使用本地MNIST数据集，数据文件应放置在 `./data/MNIST/raw/` 目录下：
- `train-images-idx3-ubyte` - 训练图像
- `train-labels-idx1-ubyte` - 训练标签
- `t10k-images-idx3-ubyte` - 测试图像
- `t10k-labels-idx1-ubyte` - 测试标签

如果本地没有数据集，可以将 `gan.py` 中的 `download=False` 改为 `download=True`。

### 运行训练
```bash
python gan.py
```

### 训练参数
- **批次大小**：64
- **训练轮数**：50
- **学习率**：0.0002 (生成器和判别器)
- **优化器**：Adam
- **噪声维度**：128

## 训练输出
训练过程中会打印每个epoch的信息：
- `d_loss`：判别器损失
- `g_loss`：生成器损失
- `D(x)`：判别器对真实图像的平均判断（接近1表示判别器能识别真实图像）
- `D(G(z))`：判别器对假图像的平均判断（接近0表示判别器能识别假图像）

理想情况下，随着训练进行：
- 生成器不断提升生成质量
- 判别器难以区分真假图像
- `D(x)` 和 `D(G(z))` 都趋向于0.5（纳什均衡）

## 结果可视化
训练完成后，程序会生成并显示一张手写数字图像样本。可以通过修改代码保存更多样本或生成图像网格。

## 改进方向
- 使用卷积神经网络 (CNN) 替代全连接层（DCGAN）
- 添加Batch Normalization提高训练稳定性
- 实现条件GAN (cGAN) 控制生成特定数字
- 使用Wasserstein GAN (WGAN) 改进训练稳定性
- 添加模型保存和加载功能
- 实现训练过程可视化和样本保存

## 参考资料
- [Goodfellow et al. 2014 - Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)
- [PyTorch官方文档](https://pytorch.org/docs/stable/index.html)
